---
title: "Logistic regression"
subtitle: "The Basics"
author: "Dr. Maria Tackett"
date: "10.23.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height =5,
	fig.width = 8,
	message = FALSE,
	warning = FALSE
)
```

class: middle, center

### [Click for PDF of slides](16-logistic.pdf)

---

### Announcements

- [Reading 08](https://www2.stat.duke.edu/courses/Fall19/sta210.001/reading/reading-08.html) for Monday

- Project Proposal **due Wed, Oct 30 at 11:59p**

---

 

### Packages

```{r,echo=T}
library(tidyverse)
library(knitr)
library(broom)
library(fivethirtyeight)
library(pROC) #ROC curves
library(questionr) #odds ratio function
```

---

### Review

- $Y$: binary response
  + 1: yes
  + 0: no
  
- $Mean(Y) = p$

- $Var(Y) = p(1-p)$

- **Odds of "yes"**: $\omega = \frac{p}{1-p}$

---

### Comparing Odds

Suppose we have two independent groups with odds $\omega_1$ and $\omega_2$

- <font class="vocab3">Odds Ratio:</font> $\phi = \frac{\omega_1}{\omega_2}$

- Use inference to assess if groups have equal odds, i.e. $\phi = 1$
  + <font class="vocab3">Hypothesis Test:</font> $$H_0: \log(\phi) = 0$$
  + <font class="vocab3">Confidence Interval:</font>
  
  $$\exp\Big\{\log(\phi) \pm z^* SE(\log(\phi))\Big\}$$

---

### Diff. in proportions vs. odds ratio

Suppose that the probability of a disease is 0.00369 in a population of unvaccinated subjects and that the probability of the disease is 0.001 in a population of vaccinated subjects.

.question[
a. What is the difference in the proportion of subjects expected to get the disease in the unvaccinated group versus the vaccinated group? 

b. What are the odds of disease without vaccine relative to the odds of disease with vaccine?
]

---

Now suppose the probability of the disease is 0.48052 in the population of unvaccinated subjects and 0.2 in the population of vaccinated subjects.

.question[
a. What is the difference in the proportion of subjects expected to get the disease in the unvaccinated group versus the vaccinated group? 

b. What are the odds of disease without vaccine relative to the odds of disease with vaccine?
]

--

.question[
Compare your responses from the two scenarios: 

1. How do the difference in proportions compare?
2. How do the odds ratios compare?
]


---


### Is it rude to recline your seat on a plane?


```{r}
flying <- fivethirtyeight::flying %>%
  drop_na(recline_rude, height, age) %>%
  mutate(
    rude = if_else(recline_rude %in% 
                     c("Somewhat", "Very"), 1, 0), 
         rude = factor(rude),
         age = factor(age, order = FALSE)) # to display in model correctly
```

- **`height`**: self-reported height in feet and inches
- **`age`**: 18-29, 30-44, 45-60, > 60
- **`rude`**: 1: yes, 0: no (Is it rude to recline your seat on a plane?)
<br><br>

Source: [*41 Percent of Fliers Think You're Rude If You Recline Your Seat*](https://fivethirtyeight.com/features/airplane-etiquette-recline-seat/)
  
---

### Opinions about flying

```{r echo=FALSE}
flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  group_by(age, rude) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```

**Is there a significant difference in the proportion of 18-29 year olds versus 30-44 year olds who think reclining a seat on a plane is rude?**
---

##`odds.ratio` function

- We will use the <font class="vocab">`odds.ratio`</font> function in the **questionr** package to compute odds ratios and the corresponding confidence interval

```{r}
#calculate odds ratio and 95% confidence interval
flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  glm(rude ~ age, data = ., family = binomial) %>%
  odds.ratio(level=0.95) %>%
  kable(format="markdown", digits = 3)
```

```{r echo=F}
or <- flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  glm(rude ~ age, data = ., family = binomial) %>%
  odds.ratio(level=0.95) %>%
  slice(2)
lb <- or$`2.5 %`
ub <- or$`97.5 %`
```


**We are 95% confident that the interval `r round(lb,3)` to `r round(ub,3)` contains the true odds ratio of 30-44 year olds versus 18-29 year olds who think reclining a seat.**

---

### Hypothesis Test for Odds Ratio

- We want to test whether two groups have equal odds, i.e. $\phi = \frac{\omega_1}{\omega_2} =1$

- <font class="vocab">Null Hypothesis: </font> $H_0: \log(\phi) = \log\big(\frac{\omega_1}{\omega_2}\big) = 0$

- <font class="vocab">Test Statistic: </font>
$$ z = \frac{\log(\hat{\phi}) - 0}{SE_0[\log(\hat{\phi})]} = \frac{\log(\hat{\phi}) - 0}{\sqrt{\frac{1}{n_1\hat{p}_c(1-\hat{p}_c)} + \frac{1}{n_2\hat{p}_c(1-\hat{p}_c)}}}$$


- <font class="vocab">p-value: </font>proportion of $N(0,1)$ distribution as extreme or more extreme than the test statistic 

---

### Standard error $SE_0[\log(\hat{\phi})]$

- The null hypothesis is that odds ratio is 1, i.e.  the proportions are equal

- To calculate standard error, we estimate $\hat{p}_c$, the sample proportion from the combined data
 
$$SE_0[\log(\hat{\phi})] =SE_0\bigg[\log\bigg(\frac{\hat{\omega}_1}{\hat{\omega}_2}\bigg)\bigg] = \sqrt{ \frac{1}{n_1\hat{p}_c(1-\hat{p}_c)} + \frac{1}{n_2\hat{p}_c(1-\hat{p}_c)}}$$

---

### Opinions about reclining seat

**Do the odds of thinking it's rude to recline a seat on a plane differ between 18-29 and 30-44 year olds?**

```{r echo=F}
p_c <- flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  summarise(p_c = round(sum(as.numeric(rude)-1)/n(),3)) %>% pull()
```

```{r echo=F}
n <- flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  group_by(age) %>%
  summarise(n = n()) %>% pull()

odds <- flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  group_by(age) %>%
  summarise(n = n(), p_hat = round(sum(as.numeric(rude)-1)/n,3),
            odds = round(p_hat/(1-p_hat),3)) %>% pull()
```

$$\begin{aligned}&H_0: \log(\phi) = 0\\
&H_a: \log(\phi) \neq 0\\\end{aligned}$$

- $\hat{p}_c$ = `r p_c`

- **18 - 29**: $n =$ `r n[1]`, $\hat{\omega} =$ `r odds[1]`

- **30 - 44**: $n =$ `r n[2]`, $\hat{\omega} =$ `r odds[2]`

.question[
1. Calculate the test statistic. 
2. Calculate p-value and make a conclusion.
]

---

class: middle, center

<font class="vocab">Looking at the odds ratio is useful...</font> 
<br><br>

.vocab[...but we want to build a model to incorporate more variables that could potentially explain the odds of a flier having the opinion that reclining a seat is rude.]

---

### Linear model? 

- We want to use a model to predict a binary response $y$

--

- Suppose we use a linear regression model to predict $y$ using some explanatory variable $x$

$$y_i = \beta_0 + \beta_1x_{i} + \epsilon_i \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)$$

--

- This model assumes that $y$ could be any continuous value; however, it can only be 0 or 1

--

- So linear regression is **<u>not</u>** appropriate

---

 

### Other model choices

Let $P(y_i=1|x_i) = p_i$ and $P(y_i=0|x_i) = 1-p_i$
<br> 
<br> 

--

Potential models for $p_i$: 
<br>

--

- **<font class="vocab">Linear:</font>** $p_i = \beta_0 + \beta_1 x_i$
  + could predict that $p_i$ is outside of $(0,1)$
--

- **<font class="vocab">Log-linear:</font>** $\log(p_i) =\beta_0 + \beta_1 x_i$
  + could predict that $p_i$ is greater than 1

---

### Logistic Regression Model 

- Suppose $P(y_i=1|x_i) = p_i$ and $P(y_i=0|x_i) = 1-p_i$

- The <font class="vocab3">logistic regression model </font> is

$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 x_i$$
<br> 


- $\log\Big(\frac{p_i}{1-p_i}\Big)$ is called the <font class="vocab3">logit</font> function


---

### Logistic Regression Model 

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 x_i$$
]
<br>

- We can calculate $p_i$ by solving the logit equation: 

$$p_i = \frac{\exp\{\beta_0 + \beta_1 x_i\}}{1 + \exp\{\beta_0 + \beta_1 x_i\}}$$

---

### Solving Logit Equation 

$$\begin{aligned}&\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 x_i\\[15pt]
\Rightarrow \hspace{8mm} &\exp\bigg\{\log\Big(\frac{p_i}{1-p_i}\Big)\bigg\} = \exp\{\beta_0 + \beta_1 x_i\}\\[15pt]
\Rightarrow \hspace{8mm} & \frac{p_i}{1-p_i} = \exp\{\beta_0 + \beta_1 x_i\} \\[15pt]
\Rightarrow \hspace{8mm}&p_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1+\exp\{\beta_0 + \beta_1 x_i\}}\\\end{aligned}$$

---

### Interpreting the intercept: $\beta_0$

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 x_i$$
]

--

- When $x=0$, log-odds of $y$ are $\beta_0$
    - Won't use this interpretation in practice

- **When $x=0$, odds of $y$ are $\exp\{\beta_0\}$**

---

### Interpreting slope coefficient $\beta_1$

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i$$
]

If $x$ is a <u>quantitative</u> predictor

- As $x_i$ increases by 1 unit, we expect the log-odds of $y$ to increase by $\beta_1$

- **As $x_i$ increases by 1 unit, we expect the odds of $y$ to multiply by a factor of $\exp\{\beta_1\}$**

--

If $x$ is a <u>categorical</u> predictor

- The difference in the log-odds between group $x$ and the baseline is $\beta_1$
- **The odds of $y$ for group $k$ are expected to be $\exp\{\beta_1\}$ times the odds of $y$ for the baseline group.**

---

### Inference for coefficients

- The standard error is the estimated standard deviation of the sampling distribution of $\hat{\beta}_1$

- We can calculate the $\color{blue}{C%}$ <font color="blue">confidence interval</font> based on the large-sample Normal approximations

- **CI for $\boldsymbol{\beta}_1$**: $$\hat{\beta}_1 \pm z^* SE(\hat{\beta}_1)$$

.alert[
**CI for $\exp\{\boldsymbol{\beta}_1\}$**: $$\exp\{\hat{\beta}_1 \pm z^* SE(\hat{\beta}_1)\}$$
  ]

---

### Estimating the coefficients

- Estimate coefficients using **maximum likelihood estimation**
  + covered in STA 250 and STA 360
<br> 

--


- <font class="vocab">Basic Idea: </font>
  + Find values of $\beta_0$ and $\beta_1$ that make observed values of $y$ the most likely to have occurred
  + Use multivariable calculus and numerical methods to estimate coefficients
--

- In this class, we will use R to estimate the coefficients

---

### Logistic regression in R

- Fit a logistic model using the Use the <font class="vocab">`glm()`</font> function
    - Set <font class="vocab">`family=binomial`</font> for a binary response variable

```{r,eval=F}
my.model <- glm(y ~ x1 + ... + xp, data = my.data,
                family = binomial)
```

- Display model with log-odds as the response
```{r eval=F}
tidy(my.model, exponentiate = FALSE) 
```

- Display model with odds as response
```{r eval=F}
tidy(my.model, exponentiate = TRUE)
```

---

### Recoding height

We want to use height to predict whether a flier will think reclining a seat on an airplane is rude. To do so, we will recode height so it's quantitative.

```{r}
flying <- flying %>% 
  separate(height, c("feet", "inches"), remove = FALSE) %>%
  mutate(height_in = case_when(
    height == "Under 5 ft." ~ 60, 
    TRUE ~ as.numeric(feet)*12 + as.numeric(inches)))
```

---

### Recoding height

```{r}
flying %>%
  select(height, height_in) %>%
  slice(1:5)
```

---

### Reclining vs. height

Use the mean-centered `height` in the model, so the intercept will have a meaningful interpretation

```{r}
flying <- flying %>%
  mutate(heightCent = height_in - mean(height_in))
```

--

```{r}
ht_model <- glm(rude ~ heightCent, data = flying, family = binomial)
kable(tidy(ht_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

---

### Reclining vs. height

```{r echo=F}
kable(tidy(ht_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

```{r echo=F}
coef <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$estimate
lb <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$conf.low
ub <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$conf.high
```

- For each additional inch taller a flier is, the odds they think reclining the seat on a plane is rude are expected to multiply by a factor of `r round(exp(coef[2]),3)`), with 95% confidence interval `r round(exp(lb[2]),3)` to `r round(exp(ub[2]),3)`.

- The odds a flier of average height thinks reclining the seat on a plane is rude are `r round(exp(coef[1]),3)` to 1, with 95% confidence interval `r round(exp(lb[1]),3)` to `r round(exp(ub[1]),3)`.

--

.question[
Is `height` a significant predictor of whether a flier thinks reclining the seat is rude?
]
---

### Reclining vs. height & age
 

```{r echo = F}
ht_age_model <- glm(rude ~ heightCent + age, data = flying, 
                    family = binomial)
kable(tidy(ht_age_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

.question[
1. Interpret the coefficient of `age30-44` in the context of the data.
2. Describe the relationship between a flier's age and the odds they think reclining the seat on a plane is rude.
]

---

class: middle, center

### Predictions & Model Fit

---

### Predictions

- We are often interested in predicting if a given observation will have a "yes" response 

- To do so, we will use the logistic regression model to predict the probability of a "yes" response for the given observation. If we have one predictor variable, then...

$$p_i = \frac{\exp(\beta_0 + \beta_1 x_i)}{1 + \exp(\beta_0 + \beta_1 x_i)}$$

- We will use the predicted probabilities to classify the observation as having a "yes" or "no" response

---

### Will the passenger think I'm rude?

- Suppose you want to recline your seat on an airplane, but you first want to determine if the passenger  behind you will think you're rude. The passenger is about 6ft tall and around 35-40 years old.

--

- Predicted log-odds that this passenger thinks reclining the seat is rude: 

$$\log\bigg(\frac{\hat{p}_i}{1-\hat{p}_i}\bigg) = 0.188 + 0.013\times(72 - 67.44) - 0.782 = -0.534$$

--

- The probability this passenger thinks reclining the seat is rude: 

$$\hat{p}_i = \frac{\exp\{ -0.534\}}{1 +  \exp\{-0.534\}} = 0.3696$$

---

### Predictions in R

```{r}
x0 <- data_frame(heightCent = (72 - 67.44), age = "30-44")
```

- **Predicted log-odds**

```{r}
predict(ht_age_model, x0) 
```

- **Predicted probabilities**

```{r}
predict(ht_age_model, x0, type = "response") 
```

---

### Will the passenger think I'm rude?

```{r}
predict(ht_age_model, x0, type = "response") 
```

The probability the passenger will think you're rude is `r round(predict(ht_age_model, x0, type = "response"), 4)`.

.question[
Based on this probability, do you expect the passenger to think you're rude? Why or not why not?
]

---


### Confusion Matrix

- We can use the estimated probabilities to predict outcomes 

- *Ex.*: Establish a threshold such that $y=1$ if predicted probability is greater than the threshold ($y=0$ otherwise)

- Determine how many observations were classified correctly and incorrectly and put the results in a $2 \times 2$ table
  + This table is the <font class="vocab3">confusion matrix</font>

- If the proportion of misclassifications is high, then we might conclude the model doesn't fit the data well

---

### Confusion Matrix

Suppose we use 0.5 as the threshold to classify responses

```{r}
threshold <- 0.5
ht_age_aug <- augment(ht_age_model, type.predict = "response")
```

```{r}
ht_age_aug %>%
  mutate(rude_predict = if_else(.fitted > threshold, "Yes", "No")) %>%
  group_by(rude, rude_predict) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```

---

### Confusion matrix

```{r echo=F}
ht_age_aug %>%
  mutate(rude_predict = if_else(.fitted > threshold, "Yes", "No")) %>%
  group_by(rude, rude_predict) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```
<br><br>

.question[ 
What proportion of observations were misclassified?]

---

### Sensitivity & Specificity

- <font class="vocab3">Sensitivity: </font>Proportion of observations with $y=1$ that have predicted probability above a specified threshold
  + Called true positive rate

- <font class="vocab3">Specificity: </font>Proportion of observations with $y=0$ that have predicted probability below a specified threshold
  + (1 - specificity) called false positive rate

- What we want: 
  + High sensitivity
  + Low values of 1-specificity

---

class: regular 

### ROC Curve

- <font class="vocab3">Receive Operating Characteristic (ROC) curve </font>: 
  + *x-axis*: $1 - \text{ specificity}$
  + *y-axis*: $\text{ Sensitivity}$ 
  
- Evaluated with a lot of different values for the threshold

- Logistic model fits well if the area under the curve (AUC) is close to 1

- ROC in R
    - Use the <font class="vocab">`roc`</font> function in the `pROC` to calculate AUC
    - Use <font class="vocab">`geom_roc`</font> layer in ggplot to plot the ROC curve

---

### Visualize ROC curve

```{r}
library(plotROC) #extension of ggplot2
ggplot(ht_age_aug, aes(d = as.numeric(rude), m = .fitted)) +
  geom_roc(n.cuts = 5, labelround = 3) + 
  geom_abline(intercept = 0)
```



---

### Area under curve

```{r echo=F}
roc_curve <- ggplot(ht_age_aug, aes(d = as.numeric(rude), m = .fitted)) +
  geom_roc(n.cuts = 5, labelround = 3) + 
  geom_abline(intercept = 0)

roc_curve
calc_auc(roc_curve)$AUC
```





