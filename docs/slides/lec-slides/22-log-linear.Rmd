---
title: "Log-linear models"
subtitle: "(Poisson regression)"
author: "Dr. Maria Tackett"
date: "11.13.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height = 4,
	fig.width = 7,
	message = FALSE,
	warning = FALSE
)
```


class: middle, center

### [Click for PDF of slides](22-log-linear.pdf)

---

### Announcements

- HW 06 **due Wed, Nov 20 at 11:59p**

- Project Regression Analysis **due Wed, Nov 20 at 11:59p**

- Looking ahead: 
    - Exam 02: Mon, Nov 25 in class
    - Exam review on Nov 20


```{r,echo=F}
library(tidyverse)
library(cowplot)
library(knitr)
library(NHANES)
library(broom)
library(pscl)
```

---

## Poisson response variables

The following are examples of scenarios with Poisson response variables:  

- Are the .vocab[number of motorcycle deaths] in a given year related to a stateâ€™s helmet laws?

- Does the .vocab[number of employers] conducting on-campus interviews during a year differ for public and private colleges?

- Does the .vocab[daily number of asthma-related visits] to an Emergency Room differ depending on air pollution indices?

- Has the .vocab[number of deformed fish] in randomly selected Minnesota lakes been affected by changes in trace minerals in the water over the last decade?

---

### Poisson Distribution 

- If $Y$ follows a Poisson distribution, then 

$$P(Y=y) = \frac{\exp\{-\lambda\}\lambda^y}{y!} \hspace{10mm} y=0,1,2,\ldots$$
<br> 

- Features of the Poisson distribution:
  + Mean and variance are equal $(\lambda)$
  + Distribution tends to be skewed right, especially when the mean is small
  + If the mean is larger, it can be approximated by a Normal distribution


---

### Simulated Poisson distributions

```{r echo = F, fig.height = 6}
set.seed(20)
sim1 <- rpois(100000,2)
sim2 <- rpois(100000,5)
sim3 <- rpois(100000,20)
sim4 <- rpois(100000,100)
pois_sim <- tibble (
  sim1 = sim1, 
  sim2 = sim2, 
  sim3 = sim3, 
  sim4 = sim4
)


p1 <- ggplot(data = pois_sim, aes(x = sim1)) +
  geom_histogram() +
  labs(x = "", title = "lambda = 2")

p2 <- ggplot(data = pois_sim, aes(x = sim2)) +
  geom_histogram() +
  labs(x = "", title = "lambda = 5")

p3 <- ggplot(data = pois_sim, aes(x = sim3)) +
  geom_histogram() +
  labs(x = "", title = "lambda = 20")

p4 <- ggplot(data = pois_sim, aes(x = sim4)) +
  geom_histogram() +
  labs(x = "", title = "lambda = 100")

plot_grid(p1, p2, p3, p4)
```

---

### Simulated Poisson distributions

```{r echo = F}
sum1 <- c(mean(sim1), var(sim1))
sum2 <- c(mean(sim2), var(sim2))
sum3 <- c(mean(sim3), var(sim3))
sum4 <- c(mean(sim4), var(sim4))
data <- rbind(sum1,sum2,sum3,sum4)
rownames(data) <- c("lambda=2", "lambda=5","lambda=20", "lambda=100")
colnames(data) <- c("Mean", "Variance")
kable(data,format="html")
```

---

### Poisson Regression

- We want $\lambda$ to be a function of predictor variables $x_1, \ldots, x_p$

--

.question[
Why is a multiple linear regression model not appropriate?
]

--

- $\lambda$ must be greater than or equal to 0 for any combination of predictor variables
- Constant variance assumption will be violated!

---

### Multiple linear regression vs. Poisson 

```{r echo = F, out.width = "75%"}
include_graphics("img/22/poisson_ols.png")
```


.footnote[Image from: [*Broadening Your Statistical Horizons*](https://bookdown.org/roback/bookdown-bysh/ch-poissonreg.html)]

---

### Poisson Regression

- If the observed values $Y_i$ are Poisson, then we can model using a <font class="vocab">Poisson regression model</font> of the form

.alert[
$$\log(\lambda_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \dots + \beta_p x_{pi}$$
]


- Note that we don't have an error term, since $\lambda$ determines the mean and variance of the Poisson random variable

---
 
### Interpreting Model Coefficients

- <font class="vocab">Slope, $\beta_j$: </font>
    - **Quantitative Predictor**:  When $x_j$ increases by one unit, the expected count of $y$ changes by a multiplicative factor of $\exp\{\beta_j\}$, holding all else constant
    
    - **Categorical Predictor**: The expected count for category $k$ is $\exp\{\beta_j\}$ times the expected count for the baseline category, holding all else constant

--

- <font class="vocab">Intercept, $\beta_0$: </font> When $x$ is 0, the expected count of $y$ is $\exp\{\beta_0\}$

---

### Example: Age, Gender, Pulse Rate

- <font class="vocab">Goal:</font> We want to use `age` and `gender` to understand variation in pulse rate
- We will use adults age 20 to 39 in the `NHANES` data set to answer this question

- **Reponse**
  + <font class="vocab">`Pulse`: </font>Number of heartbeats in 60 seconds

- **Explanatory**
  + <font class="vocab">`Age`: </font>Age in years. Subjects 80 years or older recorded as 80
      + We will use mean-centered `Age` in the model
  + <font class="vocab">`Gender`: </font>male/female

```{r echo = F}
nhanes <- NHANES::NHANES %>%
  filter(!is.na(Age), !is.na(Pulse), !is.na(Gender)) %>%
  filter(Age >= 20, Age <= 39) %>%
  mutate(ageCent = Age - mean(Age))
```

---

### Example: Age, Gender, Pulse Rate

```{r}
model1 <- glm(Pulse ~ ageCent + Gender, data = nhanes,
              family = "poisson")
kable(tidy(model1, conf.int = T),format="html")
```

.question[

1. Write the model equation.

2. Interpret the intercept in the context of the problem. 

3. Interpret the coefficient of `ageCent` in the context of the problem. 

]

---

### Drop In Deviance Test

- We would like to test if there is a significant interaction between `Age` and `Gender`

- Since we have a generalized linear model, we can use the Drop In Deviance Test (similar test to logistic regression)

```{r echo=T}
model1 <- glm(Pulse ~ ageCent + Gender, data = nhanes,
              family = "poisson")
model2 <- glm(Pulse ~ ageCent + Gender + ageCent*Gender,
              data = nhanes, family = "poisson")

anova(model1,model2,test="Chisq") %>% kable(format = "markdown")
  
```
--

- There is not sufficient evidence that the interaction is significant, so we won't include it in the model.

---

### Model Assumptions 

1. **Poisson Response**: Response variable is a count per unit of time or space

2. **Independence**: The observations are independent of one another

3. **Mean = Variance**

4. **Linearity**: $\log(\lambda)$ is a linear function of the predictors

---

### Model Diagnostics

- The raw residual for the $i^{th}$ observation, $y_i - \hat{\lambda}_i$, is difficult to interpret since the variance is equal to the mean in the Poisson distribution

- Instead, we can analyze a standardized residual called the <font class="vocab">Pearson residual</font>
$$r_i = \frac{y_i - \hat{\lambda}_i}{\sqrt{\hat{\lambda}_i}}$$

- Examine a plot of the Pearson residuals versus the predicted values and versus each predictor variable
  + A distinguishable trend in any of the plots indicates that the model is not an appropriate fit for the data

---

### Example: Age, Gender, Pulse Rate

- Let's examine the Pearson residuals for the model that includes the main effects for `Age` and `Gender`

```{r}
nhanes_aug <- augment(model1, type.predict = "response", 
                      type.residuals = "pearson")
```


```{r, echo = F}
p1 <- ggplot(data=nhanes_aug,aes(x=.fitted, y=.resid)) + 
  geom_point(alpha=0.7) + geom_hline(yintercept=0,color="red")+
  labs(title="Pearson Residuals vs. Predicted",y="Pearson Residuals",x="Predicted") + 
  theme(plot.title=element_text(hjust=0.5))

p2 <- ggplot(data=nhanes_aug, aes(x=ageCent, y=.resid)) + 
  geom_point(alpha=0.7) + geom_hline(yintercept=0,color="red")+
  labs(title="Pearson Residuals vs. Age",y="Pearson Residuals") + 
  theme(plot.title=element_text(hjust=0.5))


p3 <- ggplot(data=nhanes_aug,aes(x = Gender ,y=.resid)) + 
  geom_boxplot(fill="steelblue",color="black") +
  labs(title="Pearson Residuals vs. Gender",y="Pearson Residuals") + 
  theme(plot.title=element_text(hjust=0.5))

plot_grid(p1,p2,p3,ncol=2)

```


---

### Poisson Regression in R

- Use the <font class="vocab">`glm()`</font> function 

```{r echo=T, eval =F}
# poisson regression model
my.model <- glm(Y ~ X, data = my.data, family = poisson)
```
<br> 

```{r echo=T,eval =F}
# predicted values and Pearson residuals 
my.model_aug <- augment(my.model,
                      type.predict = "response", 
                      type.residuals = "pearson")
```

---

## Physician Visits

What factors influence the number of times someone visits a physician's office? We will use the variables `chronic`, `health`, and `insurance` to predict `visits`. We will use the `NMES1988` dataset in the AER package.



```{r}
library(AER)
data(NMES1988)
nmes1988 <- NMES1988 %>% 
  select(visits, chronic, health, insurance)
glimpse(nmes1988)
```

---

### Physicians Visits 

```{r}
visits_model <- glm(visits ~ chronic + health + insurance, 
                    data = nmes1988, family = "poisson")
```

```{r}
tidy(visits_model, conf.int = T) %>%
  kable(format = "markdown", digits = 3)
```

---

### Physician Visits 

```{r echo = F}
visits_aug <- augment(visits_model,
                      type.predict = "response", 
                      type.residual = "pearson"
)
```

Let's compare the fitted values versus the actual values: 

```{r echo = F}
p1 <- ggplot(data = visits_aug, aes(x = visits)) +
  geom_histogram() +
  labs( title = "Distribution of Observed Visits",
         x = "Number of Visits")

p2 <- ggplot(data = visits_aug, aes(x = .fitted)) +
  geom_histogram() +
  labs(title = "Distribution of Predicted Visits", 
       x = "Number of Visits")

plot_grid(p1, p2)
```

.question[
Does the model effectively predict the number of visits? What is the primary difference between the distributions of observed and predicted visits? 
]

---

### Zero-inflated Poisson

- In the original data, there are far more respondents who had zero visits to the physicians office than what's predicted by the Poisson regression model 
    - This is called .vocab[zero-inflated data]
    
- To deal with this, we will fit a model that has 2 parts: 
    1. Poisson regression for the number of doctor's visits of those who went to the physician at least one time (parameter = $\lambda$)
    2. Logistic regression to find the probability someone goes to the physican at least once (parameter = $\alpha$)
    
- We will fit this in R using the `zeroinfl` model in the **pscl** package.

---

### Zero-inflated Poisson Regression

- We will use `chronic`, `health`, and `insurance` for both components of the model
    + Note: We could use different variables for each component of the model.

```{r}
zi_model <- zeroinfl(visits ~ chronic + health + insurance | 
                      chronic + health + insurance,
                     dist = "poisson", data = nmes1988)
```

- The first set of coefficients are for the Poisson portion of the model. The second set are for the logistic portion of the model.
---

### Zero-inflated Poisson Regression

```{r}
zi_model$coefficients
```

<br>

Let's write the two parts of the model. 

---

## Predictions

```{r}
nmes1988 <- nmes1988 %>%
  mutate(pred_count = predict(zi_model, type = "count"),
  pred_zero = predict(zi_model, type = "zero"))
```


```{r}
nmes1988 %>% slice(1:10)
```


---

## References

These slides draw material from [*Broadening Your Statistical Horizons*](https://bookdown.org/roback/bookdown-bysh/ch-poissonreg.html)
