<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Multiple Linear Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Maria Tackett" />
    <link rel="stylesheet" href="sta210-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Multiple Linear Regression
## Assumptions &amp; Special Predictors
### Dr. Maria Tackett
### 09.23.19

---




class: middle, center

### [Click for PDF of slides](08-mlr-special-predictors.pdf)

---

### Announcements

- Lab 04 **due tomorrow at 11:59p**

- HW 02 **due Wednesday, 9/25 at 11:59p**

- Team Feedback #1 **due Wednesday, 9/25 at 11:59p**
    - Please provide honest and constructive feedback. This team feedback will be graded for completion.

---

### Today's agenda 

- Math details of multiple linear regression

- Assumptions for multiple linear regression 

- Special predictors

---
 
### R packages


```r
library(tidyverse)
library(knitr)
library(broom)
library(Sleuth3) # case 1202 dataset
library(cowplot) # use plot_grid function
```

---

### Starting wages data

**Explanatory**
- &lt;font class="vocab"&gt;`Educ`: &lt;/font&gt;years of Education
- &lt;font class="vocab"&gt;`Exper`: &lt;/font&gt;months of previous work Experience (before hire at bank)
- &lt;font class="vocab"&gt;`Female`: &lt;/font&gt;1 if female, 0 if male
- &lt;font class="vocab"&gt;`Senior`: &lt;/font&gt;months worked at bank since hire
- &lt;font class="vocab"&gt;`Age`: &lt;/font&gt;Age in months

**Response**
- &lt;font class="vocab"&gt;`Bsal`: &lt;/font&gt;annual salary at time of hire

---

### Starting wages 




```r
glimpse(wages)
```

```
## Observations: 93
## Variables: 6
## $ Bsal   &lt;int&gt; 5040, 6300, 6000, 6000, 6000, 6840, 8100, 6000, 6000, 690…
## $ Senior &lt;int&gt; 96, 82, 67, 97, 66, 92, 66, 82, 88, 75, 89, 91, 66, 86, 9…
## $ Age    &lt;int&gt; 329, 357, 315, 354, 351, 374, 369, 363, 555, 416, 481, 33…
## $ Educ   &lt;int&gt; 15, 15, 15, 12, 12, 15, 16, 12, 12, 15, 12, 15, 15, 15, 1…
## $ Exper  &lt;dbl&gt; 14.0, 72.0, 35.5, 24.0, 56.0, 41.5, 54.5, 32.0, 252.0, 13…
## $ Female &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, …
```

---


### Regression model


```r
bsal_model &lt;- lm(Bsal ~ Senior + Age + Educ + Exper + Female, 
            data=wages)
kable(tidy(bsal_model,conf.int=TRUE),format="html",digits=3)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.high &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4981.434 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7574.353 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -33.108 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -12.056 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.801 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.063 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 42.887 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 141.725 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.597 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.598 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1024.255 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -511.571 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

class: middle, center

## Math Details 


---

### Regression Model 

- The multiple linear regression model assumes 

.alert[
`$$y|x_1, x_2,  \ldots, x_p \sim N(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p, \sigma^2)$$`
]

--

- For a given observation `\((x_{i1}, x_{i2}, \ldots, x_{ip}, y_i)\)`, we can rewrite the previous statement as 

.alert[
`$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \dots + \beta_p x_{ip} + \epsilon_{i} \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)$$`
]
---

### Estimating `\(\sigma^2\)`

- For a given observation `\((x_{i1}, x_{i2}, \ldots,x_{ip}, y_i)\)` the residual is 

.alert[
`$$e_i = y_{i} - (\hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \hat{\beta}_{2} x_{i2} + \dots + \hat{\beta}_p x_{ip})$$`
]

--

- The estimated value of the regression variance , `\(\sigma^2\)`, is 

.alert[
`$$\hat{\sigma}^2  = \frac{RSS}{n-p-1} = \frac{\sum_{i=1}^ne_i^2}{n-p-1}$$`
]

---

### Estimating Coefficients 

- One way to estimate the coefficients is by taking partial derivatives of the formula

`$$\sum_{i=1}^n e_i^2 = \sum_{i=1}^{n}[y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} \dots + \beta_p x_{ip})]^2$$`

--

- This produces messy formulas, so instead we can use matrix notation for multiple linear regression and estimate the coefficients using rules from linear algebra. 
    - For more details, see Section 1.2 of the textbook and the supplemental notes [Matrix Notation for Multiple Linear Regression](https://github.com/sta210-fa19/supplemental-notes/blob/master/regression-basics-matrix.pdf)
    - **Note:** You are **&lt;u&gt;not&lt;/u&gt;** required to know matrix notation for MLR in this class

---

class: middle, center

## Assumptions 

---

### Assumptions 

Inference on the regression coefficients and predictions are reliable only when the regression assumptions are reasonably satisfied: 

1. &lt;font class="vocab"&gt;Linearity: &lt;/font&gt; Response variable has a linear relationship with the predictor variables in the model

2. &lt;font class="vocab"&gt;Constant Variance: &lt;/font&gt;The regression variance is the same for all set of predictor variables `\((x_1, \ldots, x_p)\)`

3. &lt;font class="vocab"&gt;Normality: &lt;/font&gt; For a given set of predictors `\((x_1, \ldots, x_p)\)`, the response, `\(y\)`, follows a Normal distribution around its mean 

4. &lt;font class="vocab"&gt;Independence: &lt;/font&gt;All observations are independent

---

### Scatterplots 

- Look at a scatterplot of the response variable vs. each of the predictor variables in the exploratory data analysis before calculating the regression model 

- This is a good way to check for obvious departures from linearity 
    - Could be an indication that a higher order term or transformation is needed

---

### Residual Plots

- **Plot the residuals vs. the predicted values**
    - Can expose issues such at outliers or non-constant variance
    - Should have no systematic pattern 
    
- **Plot the residuals vs. each of the predictors**
    - Can expose issues between the response and a predictor variable that didn't show in the exploratory data analysis
    - Use box plots to plot residuals versus categorical predictor variables
    - Should have no systematic pattern

- **Plot a histogram and QQ-plot of the residuals**
    - Check normality 

---

### Scatterplots


```r
pairs(Bsal ~ Senior + Age + Educ + Exper, data = wages, 
      lower.panel = NULL)
```

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

- Only include a 4 - 5 variables in a single pairs plot; otherwise, the scatterplots are too small to be readable
---

### Residuals vs. Predicted Values


```r
wages &lt;- wages %&gt;% 
  mutate(predicted = predict.lm(bsal_model), residuals = resid(bsal_model))
ggplot(data=wages,aes(x=predicted, y=residuals)) + 
  geom_point() + 
  geom_hline(yintercept=0,color="red") +
  labs(title="Residuals vs. Predicted Values") 
```

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---

### Residuals vs. Predictors

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---

### Residuals vs. Predictors 


```r
ggplot(data=wages,aes(x=Female,y=residuals)) + 
  geom_boxplot() + 
  geom_hline(yintercept=0,color="red") +
  labs(x = "Female", 
       y="Residuals")
```

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---

### Normality of Residuals

.pull-left[
&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;
]


---

class: middle, center

## Special Predictors

---

### Interpreting the Intercept 

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.question[
- Interpret the intercept. 

- Is this interpretation meaningful? Why or why not?
]

---


### Mean-Centered Variables

- To have a meaningful interpretation of the intercept, use **mean-centered** predictor variables in the model (quantitative predictors only)

- A &lt;font class = "vocab"&gt;mean-centered variable&lt;/font&gt; is calculated by subtracting the mean from each value of the variable, i.e. `$$x_{ip} - \bar{x}_{.p}$$`

- Now the intercept is interpreted as the expected value of the response at the mean value of all quantitative predictors

---

### Salary: Mean-Centered Variables


```r
wages &lt;- wages %&gt;%
  mutate(SeniorCent = Senior - mean(Senior), 
         AgeCent = Age-mean(Age), 
         EducCent = Educ - mean(Educ), 
         ExperCent = Exper - mean(Exper))
```

.pull-left[
&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;
]


---

 

### Salary: Mean-Centered Variables



.question[
**Application Exercise**: Fit the regression model using the mean-centered variables. 
- How did the model stay the same? 
- How did the model change?
]

---

### Quadratic Terms

 - Sometimes the response variable may have a quadratic relationship with one or more predictor variables
    - You can see this in a plot of the residuals vs. a predictor variable 
- Include quadratic terms in the model to capture the relationship 

- &lt;font class="vocab"&gt;Good Practice:&lt;/font&gt; Also include all lower order terms even if they are not significant. 
    - This helps with interpretation 
  
- You can show quadratic relationships by plotting the predicted mean response for different values of the predictors variable

- Note: The same ideas apply for higher-order polynomial terms

---

Below are plots of the residuals versus each quantitative predictor variable. 

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

.question[
Which variables (if any) appear to have a quadratic relationship with `Bsal`?
]

---

### Indicator (dummy) variables


- Suppose there is a categorical variable with `\(k\)` levels (categories)

- Make `\(k\)` indicator variables (also known as dummy variables)

- Use `\(k-1\)` of the indicator variables in the model
    - Can't uniquely estimate all `\(k\)` variables at once if the intercept is in the model
    
- Level that doesn't have a variable in the model is called the &lt;font class="vocab3"&gt;baseline&lt;/font&gt;

- Coefficients interpreted as the change in the mean of the response over the baseline

---

### Indicator variables when `\(k=2\)`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.high &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5924.007 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 99.659 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 59.443 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5725.925 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6122.090 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1024.255 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -511.571 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; SeniorCent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -33.108 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -12.056 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; AgeCent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.801 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.063 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; EducCent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 42.887 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 141.725 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ExperCent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.597 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.598 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.question[
- Write the model equation used to predict the starting salary for males.

- Write the model equation used to predict the starting salary for females.
]

---

### Indicator variables when `\(k &gt; 2\)`

**Application Exercise**: Fit a regression model with Education treated as a categorical variable. 

.question[
- What is the baseline for Education?

- Interpret the coefficient for `EducCat16`.

- What is your conclusion from the p-value of `EducCat16`?

- Write the model equation for those with 8 years of education. 

- Write the model equation for those with 16 years of education. 
]
---

### Interaction Terms

- **Case**: Relationship of the predictor variable with the response depends on the value of another predictor variable
  + This is an &lt;font class="vocab3"&gt;interaction effect&lt;/font&gt;
  
- Create a new interaction variable that is one predictor variable times the other in the interaction 

- &lt;font class="vocab"&gt;Good Practice:&lt;/font&gt; When including an interaction term, also include the associated **main effects** (each predictor variable on its own) even if they are not statistically significant
---

### Interaction effects

&lt;img src="08-mlr-special-predictors_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

.question[
Do you think there is a significant interaction effect between `Female` and `Senior`? Why or why not?
]


---

### Before next class

- Review [Reading 03](https://www2.stat.duke.edu/courses/Fall19/sta210.001/reading/reading-03.html) on special predictors
- [Reading 04](https://www2.stat.duke.edu/courses/Fall19/sta210.001/reading/reading-04.html) on transformations
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
